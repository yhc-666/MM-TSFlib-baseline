开始训练 - 任务: pheno
使用wandb记录实验 - 项目: MM-TSFlib-EHR, 实验名: pheno_d256_h4_l2_lr5e-05
训练进度:   1%|▎                             | 5/500 [06:10<10:10:43, 74.03s/it, train_loss=0.399, val_loss=0.404, val_AUROC=0.667]
Traceback (most recent call last):                                                                                                 
Epoch 1: train_loss=0.432 val_loss=0.413 val_metrics={'macro_AUROC': 0.645916204161819, 'macro_AUPRC': 0.27002698736430647, 'micro_F1': 0.16938423941348504, 'macro_F1': 0.09416041195140408}
Epoch 2: train_loss=0.411 val_loss=0.408 val_metrics={'macro_AUROC': 0.6548839414682005, 'macro_AUPRC': 0.2774615634647884, 'micro_F1': 0.1312460334250053, 'macro_F1': 0.07623707650296509}
Epoch 3: train_loss=0.406 val_loss=0.406 val_metrics={'macro_AUROC': 0.6608406675261812, 'macro_AUPRC': 0.28190149565280703, 'micro_F1': 0.18137312961427612, 'macro_F1': 0.08769967757910739}
Epoch 4: train_loss=0.402 val_loss=0.407 val_metrics={'macro_AUROC': 0.6649100742159532, 'macro_AUPRC': 0.28627233158260545, 'micro_F1': 0.1347176288357684, 'macro_F1': 0.08372902986756663}
Epoch 5: train_loss=0.399 val_loss=0.404 val_metrics={'macro_AUROC': 0.6674771058880952, 'macro_AUPRC': 0.2899446769286827, 'micro_F1': 0.16027106466361854, 'macro_F1': 0.09367214752797448}
  File "/home/ubuntu/hcy50662/MM-TSFlib-baseline/scripts/run_ehr.py", line 63, in <module>
    main()
  File "/home/ubuntu/hcy50662/MM-TSFlib-baseline/scripts/run_ehr.py", line 58, in main
    exp.train(setting)
  File "/home/ubuntu/hcy50662/MM-TSFlib-baseline/exp/exp_ehr.py", line 121, in train
    tokens = self.tokenizer(list(texts), return_tensors='pt', padding=True, truncation=True, max_length=self.args.max_seq_len).input_ids.to(self.device)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py", line 2867, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py", line 2955, in _call_one
    return self.batch_encode_plus(
  File "/home/ubuntu/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py", line 3156, in batch_encode_plus
    return self._batch_encode_plus(
  File "/home/ubuntu/.local/lib/python3.10/site-packages/transformers/tokenization_utils_fast.py", line 541, in _batch_encode_plus
    encodings = self._tokenizer.encode_batch(
KeyboardInterrupt
